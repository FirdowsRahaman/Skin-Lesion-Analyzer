{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbQPVrsgrPdv"
   },
   "source": [
    "# **Skin Lesion Analyzer with Deep Learning**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YqwfEeE1av1"
   },
   "source": [
    "### **Outline**\n",
    "Use these links to jump to specific sections of this project.\n",
    "\n",
    "1. Import Packages\n",
    "2. Load and Transform the Dataset\n",
    "3. Model Development\n",
    "4. Model Training \n",
    "5. Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaH4iOVSra0s"
   },
   "source": [
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbuL5F7rrRs9"
   },
   "outputs": [],
   "source": [
    "# python libraties\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# tensorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zamPLMdj2zJR"
   },
   "source": [
    "### 2. Load and Transform the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d53dRWzC3AtS"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "class DatasetBuilder():\n",
    "    def __init__(self, base_dir, csv_file):\n",
    "        self.base_dir = base_dir\n",
    "        self.csv_file = csv_file\n",
    "        \n",
    "    def split_and_transform_df(self, base_dir, csv_file):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        image_path_dict = {os.path.splitext(os.path.basename(x))[0]: x \n",
    "                       for x in glob.glob(os.path.join(base_dir, '*', '*.jpg'))}\n",
    "        \n",
    "        label_dict = {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3,\n",
    "                      'mel': 4, 'nv': 5, 'vasc': 6}\n",
    "        \n",
    "        df['image_path'] = df['image_id'].map(image_path_dict.get)\n",
    "        df['label_id'] = df['dx'].map(label_dict.get)\n",
    "    \n",
    "        train_df, val_df = train_test_split(df, test_size=0.15)\n",
    "        train_df, test_df = train_test_split(train_df, test_size=0.10)\n",
    "        return train_df, val_df\n",
    "    \n",
    "    def decode_image(self, filename, label, image_size=(224, 224)):\n",
    "        bits = tf.io.read_file(filename)\n",
    "        image = tf.image.decode_jpeg(bits, channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = tf.image.resize(image, image_size)\n",
    "        return image, label\n",
    "    \n",
    "    def input_fn(self, dataframe, batch_size=32):\n",
    "        image_list = dataframe.image_path.values\n",
    "        label_list = dataframe.label_id.values\n",
    "    \n",
    "        ds = (tf.data.Dataset\n",
    "                .from_tensor_slices((image_list, label_list))\n",
    "                .map(self.decode_image, num_parallel_calls=AUTOTUNE)\n",
    "                .cache()\n",
    "                .repeat()\n",
    "                .shuffle(buffer_size = 10 * batch_size)\n",
    "                .batch(batch_size)\n",
    "                .prefetch(AUTOTUNE))\n",
    "        return ds\n",
    "    \n",
    "    def create_dataset(self):\n",
    "        train_df, val_df = self.split_and_transform_df(self.base_dir, self.csv_file)\n",
    "        train_ds = self.input_fn(train_df)\n",
    "        val_ds = self.input_fn(val_df)\n",
    "        return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVIpA6tJ3Tgs"
   },
   "source": [
    "### 3. Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvDFXQ_q3jZn"
   },
   "outputs": [],
   "source": [
    "image_shape = (224, 224, 3)\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "base_model = DenseNet121(input_shape=image_shape, \n",
    "                         include_top=False,\n",
    "                         weights='imagenet')\n",
    "base_model.trainable = True\n",
    "\n",
    "image_input = keras.Input(shape=image_shape)\n",
    "x = base_model(image_input)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(7, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs=image_input, outputs=x)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=base_learning_rate/10),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBB-6bGk4yao"
   },
   "source": [
    "### 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSQPxrE84l4s"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(params):\n",
    "    csv_file = params['csv_file']\n",
    "    base_dir = params['base_dir']\n",
    "    batch_size = params['batch_size']\n",
    "    num_epochs = params['num_epochs']\n",
    "    train_steps = params['train_steps']\n",
    "    val_steps = params['val_steps']\n",
    "\n",
    "    builder = DatasetBuilder(base_dir, csv_file)\n",
    "    train_ds, val_ds = builder.create_dataset()\n",
    "    \n",
    "    history = model.fit(train_ds,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        validation_data=val_ds,\n",
    "                        steps_per_epoch=train_steps,\n",
    "                        validation_steps=val_steps)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzlUVJG75kTU"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'csv_file': '../input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv',\n",
    "    'base_dir': '../input/skin-cancer-mnist-ham10000',\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 10,\n",
    "    'train_steps': 239,\n",
    "    'val_steps': 46\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVrOfLuU5nzF"
   },
   "outputs": [],
   "source": [
    "train_and_evaluate(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uf2tId25tbZ"
   },
   "source": [
    "### 5. Prediction and Evaluation "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Skin Lesion Analyzer Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
