{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbQPVrsgrPdv"
   },
   "source": [
    "# **Skin Lesion Analyzer with Deep Learning**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YqwfEeE1av1"
   },
   "source": [
    "### **Outline**\n",
    "Use these links to jump to specific sections of this project.\n",
    "\n",
    "1. Import Packages\n",
    "2. Load and Transform the Dataset\n",
    "3. Model Development\n",
    "4. Model Training \n",
    "5. Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaH4iOVSra0s"
   },
   "source": [
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AbuL5F7rrRs9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zamPLMdj2zJR"
   },
   "source": [
    "### 2. Load and Transform the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "d53dRWzC3AtS"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "class DatasetBuilder():\n",
    "    def __init__(self, base_dir, csv_file):\n",
    "        self.base_dir = base_dir\n",
    "        self.csv_file = csv_file\n",
    "        \n",
    "    def transform_df(self, base_dir, csv_file):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        image_path_dict = {os.path.splitext(os.path.basename(x))[0]: x \n",
    "                       for x in glob.glob(os.path.join(base_dir, '*', '*.jpg'))}\n",
    "        label_dict = {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3,\n",
    "                      'mel': 4, 'nv': 5, 'vasc': 6}\n",
    "        df['image_path'] = df['image_id'].map(image_path_dict.get)\n",
    "        df['label_id'] = df['dx'].map(label_dict.get)\n",
    "        return df\n",
    "    \n",
    "    def split_df(self):\n",
    "        dataframe = self.transform_df(self.base_dir, self.csv_file)\n",
    "        train_df, val_df = train_test_split(dataframe, test_size=0.15)\n",
    "        train_df, test_df = train_test_split(train_df, test_size=0.10)\n",
    "        return train_df, val_df, test_df\n",
    "    \n",
    "    def get_labels(self, dataframe):\n",
    "        label_list = dataframe.label_id.values\n",
    "        labels = to_categorical(label_list, num_classes=7)\n",
    "        return labels\n",
    "    \n",
    "    def decode_image(self, filename, label=None, image_size=(224, 224)):\n",
    "        bits = tf.io.read_file(filename)\n",
    "        image = tf.image.decode_jpeg(bits, channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = tf.image.resize(image, image_size)\n",
    "        return image, label\n",
    "    \n",
    "    def input_fn(self, dataframe, batch_size=32, mode=None):\n",
    "        image_list = dataframe.image_path.values\n",
    "        labels = self.get_labels(dataframe)\n",
    "        ds = (tf.data.Dataset     \n",
    "                .from_tensor_slices((image_list, labels))\n",
    "                .map(self.decode_image, num_parallel_calls=AUTOTUNE)\n",
    "                .cache()\n",
    "                .repeat()\n",
    "                .shuffle(buffer_size = 10 * batch_size)\n",
    "                .batch(batch_size)\n",
    "                .prefetch(AUTOTUNE))\n",
    "        return ds\n",
    "\n",
    "    def create_dataset(self):\n",
    "        train_df, val_df, test_df = self.split_df()\n",
    "        train_ds = self.input_fn(train_df)\n",
    "        val_ds = self.input_fn(val_df)\n",
    "        return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVIpA6tJ3Tgs"
   },
   "source": [
    "### 3. Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lvDFXQ_q3jZn"
   },
   "outputs": [],
   "source": [
    "image_shape = (224, 224, 3)\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "base_model = DenseNet121(input_shape=image_shape, \n",
    "                         include_top=False,\n",
    "                         weights='imagenet')\n",
    "base_model.trainable = True\n",
    "\n",
    "image_input = keras.Input(shape=image_shape)\n",
    "x = base_model(image_input)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(7, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs=image_input, outputs=x)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=base_learning_rate/10),\n",
    "                loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBB-6bGk4yao"
   },
   "source": [
    "### 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SSQPxrE84l4s"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(params):\n",
    "    csv_file = params['csv_file']\n",
    "    base_dir = params['base_dir']\n",
    "    batch_size = params['batch_size']\n",
    "    num_epochs = params['num_epochs']\n",
    "    train_steps = params['train_steps']\n",
    "    val_steps = params['val_steps']\n",
    "\n",
    "    builder = DatasetBuilder(base_dir, csv_file)\n",
    "    train_ds, val_ds = builder.create_dataset()\n",
    "    \n",
    "    history = model.fit(train_ds,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        validation_data=val_ds,\n",
    "                        steps_per_epoch=train_steps,\n",
    "                        validation_steps=val_steps)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lzlUVJG75kTU"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'csv_file': '../input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv',\n",
    "    'base_dir': '../input/skin-cancer-mnist-ham10000',\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 10,\n",
    "    'train_steps': 239,\n",
    "    'val_steps': 46\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVrOfLuU5nzF",
    "outputId": "1da93943-8ec8-41b1-8cb4-08667fdaae4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "239/239 [==============================] - 99s 413ms/step - loss: 1.6960 - accuracy: 0.4799 - val_loss: 1.6371 - val_accuracy: 0.6698\n",
      "Epoch 2/10\n",
      "239/239 [==============================] - 88s 368ms/step - loss: 1.4594 - accuracy: 0.7257 - val_loss: 1.4526 - val_accuracy: 0.7609\n",
      "Epoch 3/10\n",
      "239/239 [==============================] - 88s 369ms/step - loss: 1.4012 - accuracy: 0.7690 - val_loss: 1.3835 - val_accuracy: 0.7908\n",
      "Epoch 4/10\n",
      "239/239 [==============================] - 88s 368ms/step - loss: 1.3645 - accuracy: 0.7948 - val_loss: 1.3551 - val_accuracy: 0.8043\n",
      "Epoch 5/10\n",
      "239/239 [==============================] - 88s 368ms/step - loss: 1.3384 - accuracy: 0.8227 - val_loss: 1.3419 - val_accuracy: 0.8077\n",
      "Epoch 6/10\n",
      "239/239 [==============================] - 88s 368ms/step - loss: 1.3164 - accuracy: 0.8477 - val_loss: 1.3302 - val_accuracy: 0.8288\n",
      "Epoch 7/10\n",
      "239/239 [==============================] - 88s 369ms/step - loss: 1.2973 - accuracy: 0.8673 - val_loss: 1.3320 - val_accuracy: 0.8281\n",
      "Epoch 8/10\n",
      "239/239 [==============================] - 88s 369ms/step - loss: 1.2844 - accuracy: 0.8779 - val_loss: 1.3159 - val_accuracy: 0.8458\n",
      "Epoch 9/10\n",
      "239/239 [==============================] - 88s 368ms/step - loss: 1.2639 - accuracy: 0.9081 - val_loss: 1.3073 - val_accuracy: 0.8567\n",
      "Epoch 10/10\n",
      "239/239 [==============================] - 88s 369ms/step - loss: 1.2506 - accuracy: 0.9246 - val_loss: 1.3145 - val_accuracy: 0.8444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f63044ce0b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dydoSPlHFRD4"
   },
   "outputs": [],
   "source": [
    "model_export_path = '/saved_model'\n",
    "tf.saved_model.save(model, model_export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uf2tId25tbZ"
   },
   "source": [
    "### 5. Prediction and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "74GEGH5d3ctG"
   },
   "outputs": [],
   "source": [
    "def preprocess_input(params):\n",
    "    csv_file = params['csv_file']\n",
    "    base_dir = params['base_dir']\n",
    "    \n",
    "    builder = DatasetBuilder(base_dir, csv_file)\n",
    "    _, _, test_df = builder.split_df()\n",
    "    image_list = test_df.image_path.values\n",
    "    \n",
    "    image = []\n",
    "    for img in image_list:\n",
    "        img2array, _ = builder.decode_image(img)\n",
    "        img_batch = np.expand_dims(img2array, axis=0)\n",
    "        image.append(img_batch)\n",
    "    \n",
    "    labels = builder.get_labels(test_df)\n",
    "    images = np.vstack(image)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "t0IAHXXe33uQ"
   },
   "outputs": [],
   "source": [
    "test_images, test_labels = preprocess_input(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pnKVKHZX38kE"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qkP2Dob746nc"
   },
   "outputs": [],
   "source": [
    "true_labels = pd.DataFrame(data = test_labels) \n",
    "predicted_labels = pd.DataFrame(data = predictions) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Skin Lesion Analyzer Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
